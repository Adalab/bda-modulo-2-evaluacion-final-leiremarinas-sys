 Ejercicio 1: Evaluaci贸n Final - M贸dulo 2

Este proyecto representa la culminaci贸n pr谩ctica del M贸dulo 2 del bootcamp de An谩lisis de Datos de Adalab. Documenta un flujo completo de Extracci贸n, Transformaci贸n, Carga y An谩lisis de Datos (ETL), cuyo objetivo es obtener datos de una fuente externa, cargarlos en una base de datos relacional y realizar an谩lisis estad铆sticos y de consulta.

 1. Archivos del Repositorio Archivo Funci贸n Principal

Leire_Ejercicio1.ipynbEs el notebook de Python que orquesta el proyecto. 
Contiene el c贸digo para la Descarga, Transformaci贸n, Carga de datos a MySQL y la Ejecuci贸n de todas las consultas de an谩lisis.

Ejercicio1_Fase4.sql Archivo centralizado que almacena las sentencias SELECT dise帽adas para el an谩lisis inicial.

README.md Documentaci贸n oficial del flujo de trabajo, las fases del proyecto y los requerimientos.

2. Flujo de Trabajo y Fases del ProyectoEl proceso se lleva a cabo en tres fases principales, con un paso de correcci贸n y ampliaci贸n posterior para asegurar la integridad de los datos.

Fase 1: Extracci贸n y Transformaci贸n (ET)Esta fase inicial se encarga de preparar los datos para su inserci贸n en MySQL.
Extracci贸n: Se utiliza la librer铆a requests de Python para descargar un archivo de datos en formato JSON desde una URL externa.
Transformaci贸n: Los datos se cargan en un DataFrame de Pandas. Se realiza la limpieza y adecuaci贸n de tipos de datos, crucialmente mapeando los valores nulos (NaN o None) a valores compatibles con SQL para evitar errores de inserci贸n.

Fase 2: Se crea la conexi贸n con SQL y la BD Adalab_Peliculas

FASE 3: Esta fase es responsable de transferir masivamente los datos limpios a la base de datos MySQL.Conexi贸n: El notebook establece una conexi贸n con la base de datos Adalab_Peliculas, y crea la tabla peliculas dentro de la misma.
Inserci贸n Masiva: Se utiliza la funci贸n executemany del conector de MySQL para Python.

FASE 4: Consultas sobre la tabla creada con los datos importados de la API. EN este caso las consultas se realizan en un archivo SQL llamado Ejercicio1_Fase4.sql y despu茅s se automatiza en python la ejecuci贸n de todas las queries con sus reusltados



锔 Correcci贸n y Ampliaci贸n de la Carga (Post-Inicial)

Durante la importaci贸n inicial, no se incluy贸 la columna Subtitulos en la tabla peliculas.
Para corregir esto y asegurar que todos los datos est茅n disponibles para el an谩lisis, se ejecutaron pasos adicionales desde el notebook:

Modificaci贸n de la Estructura: Se utiliz贸 el comando ALTER TABLE desde Python para a帽adir la columna Subtitulos a la tabla de MySQL.
Preparaci贸n del Dato: Los datos de subt铆tulos (originalmente listas de Python) se transformaron a una 煤nica cadena de texto (string) separada por comas, compatible con el tipo VARCHAR de MySQL.
Actualizaci贸n de Datos: Se ejecut贸 una sentencia UPDATE masiva (utilizando executemany) para rellenar la nueva columna Subtitulos en todas las filas de la tabla.

Tras la correcci贸n de la columna, se a帽adi贸 una consulta adicional y espec铆fica desde Python para responder a la query faltante: "驴Cu谩ntas pel铆culas incluyen subt铆tulos en espa帽ol?". Esta consulta utiliza el operador LIKE para buscar la subcadena 'es' en la nueva columna Subtitulos.Resultados: Los resultados del an谩lisis son cargados y presentados como DataFrames de Pandas dentro del notebook.


 Ejercicio 2: Evaluaci贸n Final - M贸dulo 2

Diferentes queries sobre la Base de Datos Sakila


